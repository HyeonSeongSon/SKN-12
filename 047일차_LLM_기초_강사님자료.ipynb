{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVhlXTiJHDTp",
        "outputId": "13b3a32a-5e4a-4ca5-d2af-da9020db9e4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "예, API가 정상적으로 동작하는지 확인하려면 해당 API를 호출하고 반환되는 결과를 확인해야 합니다. 만약 예상한 대로의 결과를 받고 정상적으로 동작하는 것을 확인했다면, API가 잘 동작하고 있는 것으로 판단할 수 있습니다. 그러나 만약 원하는 결과를 얻지 못하거나 에러가 발생한다면 API에 문제가 있을 수 있습니다. 추가적인 테스트와 디버깅을 통해 문제를 해결해야 합니다.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] =\n",
        "\n",
        "client = OpenAI(api_key='api-key')\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"API 잘 동작합니까?\",\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z9LOZaITMqy"
      },
      "source": [
        "프롬프트 엔지니어링\n",
        "```\n",
        "맥락을 함께 주고 : 대상, 목적, 상황을 같이 설명\n",
        "예시포함(Few-shot) : 기대하는 결과물의 형태를 미리 보여준다\n",
        "단계별 사고 유도 : 단계별로 알려줘, 알기쉽게 설명해줘\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYP5-f-QUNOK"
      },
      "source": [
        "개별서비스 구축\n",
        "```\n",
        "사용자 맞춤형 쳇봇\n",
        "실시간 질의 응답시스템\n",
        "문서 자동 요약 및 분석\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc1Z3oJcUUnb"
      },
      "source": [
        "프롬프트 엔지니어링 + 파인튜닝\n",
        "```\n",
        "프롬프트 세심하게 작성\n",
        "oepnai 파인튜닝 api를 통해\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvCTO-3TGsL2"
      },
      "source": [
        "외부정보 연동(Vector DB)\n",
        "```\n",
        "사용자가 입력-> 외부 문서 내용을 함께 제공(프롬프트기반)\n",
        "RAG 방식으로 VectorDB 연동\n",
        "```\n",
        "VectorDB\n",
        "```\n",
        "문서를 임베딩해서 검색할수 있는 데이터베이스\n",
        "대표적인 VectorDB : Chroma ,FAISS, 등\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnzyrqwsWILr"
      },
      "source": [
        "ChatGPT API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vBgtuDFVkpc"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"api-key\"\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpGlmGRRXYnb"
      },
      "source": [
        "```\n",
        "system : 모델의 성격이나 톤을 설정한다. (친절한 조수, 인공지능 전문가, 학습전문가, 등등)\n",
        "user : 사용자의 입력 메세지\n",
        "assistant : 모델의 이전 응답내용\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMXbrz2wWkfs",
        "outputId": "7d7c97da-782d-4c2a-d2b3-e7b4d06134ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "시간여행용 타임머신과 과거 언어를 이해할 수 있는 신비한 번역기! 그리고 권투글러브로 가족 관계나 시대적 미래 충격으로부터 몸을 보호해야 할 필요가 있어요.\n"
          ]
        }
      ],
      "source": [
        "# gpt 대화 객체 생성 - chatgpt 대화창\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\",\"content\" : \"너는 위트있는 AI비서야, 설명도 잘하고 농담도 잘해\"},\n",
        "        {\"role\":\"user\",\"content\" : \"내가 과거로 가면 꼭 가야할 곳이 어디야?\"},\n",
        "        {\"role\":\"assistant\",\"content\" : \"기원전 5세기 아테네 – 민주주의와 철학(소크라테스, 플라톤)의 탄생지.\"},\n",
        "        {\"role\":\"user\",\"content\" : \"거기가서 잘 살려면 뭘 준비해 가야해?\"}\n",
        "    ]\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wS_WWTKZ9xD"
      },
      "source": [
        "api 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gZaPhAgpaNn4",
        "outputId": "5f7584bb-e54e-4b98-e44e-8e066e688e20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=0.8->flask-ngrok) (3.0.2)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ],
      "source": [
        "!pip install flask-ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "En96VaGPbQX7",
        "outputId": "ccf58795-f4e9-4e30-bc78-b2659befd08d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "Exception in thread Thread-8:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 198, in _new_conn\n",
            "    sock = connection.create_connection(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
            "    response = self._make_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
            "    conn.request(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 445, in request\n",
            "    self.endheaders()\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 1298, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 1058, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 996, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 276, in connect\n",
            "    self.sock = self._new_conn()\n",
            "                ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 213, in _new_conn\n",
            "    raise NewConnectionError(\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ea0aa3cd150>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 667, in send\n",
            "    resp = conn.urlopen(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
            "    retries = retries.increment(\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/retry.py\", line 519, in increment\n",
            "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ea0aa3cd150>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1401, in run\n",
            "    self.function(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flask_ngrok.py\", line 70, in start_ngrok\n",
            "    ngrok_address = _run_ngrok()\n",
            "                    ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flask_ngrok.py\", line 35, in _run_ngrok\n",
            "    tunnel_url = requests.get(localhost_url).text  # Get the tunnel information\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/api.py\", line 73, in get\n",
            "    return request(\"get\", url, params=params, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/api.py\", line 59, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 700, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ea0aa3cd150>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, render_template, jsonify, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    # return render_template(\"index.html\")\n",
        "    answer = 'test context'\n",
        "    return jsonify({\"answer\":answer})\n",
        "\n",
        "app.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U-VfopQfnJw"
      },
      "source": [
        "스트리밍\n",
        "```\n",
        "gpt의 응답을 바로 바로 확인 작성되는데로 순차적으로 확인\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9Czx9rYWpFW"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "openai.api_key = 'api-key'\n",
        "client = openai.OpenAI()\n",
        "user_prompt = \"행복이란 무엇인가요? 철학적으로 설명해줘\"\n",
        "pre_prompt = \"한국어로 친절하고 자세하게 답변해줘 \\n\\n\"\n",
        "stream = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"너는 고상한 철학자야\"},\n",
        "        {\"role\": \"user\", \"content\": pre_prompt+user_prompt}\n",
        "    ],\n",
        "    stream=True,\n",
        "    temperature=0.6,  # 창의성 조절, 높은수록 창의적 낮을수록 결정적\n",
        "    top_p=1,  # (전체  학률 분포 1은 제한없음)\n",
        "    frequency_penalty=0,  # 같은 단어 반복시 감정 높을수록 반복 억제\n",
        "    presence_penalty=0,   # 주제반복 여부에 따른 감점, 높으면 새로운 주제로 유도\n",
        "    max_tokens = 2048\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WlMugGYQfduL",
        "outputId": "c439af2c-56d3-472a-df1d-5ec578917ba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "행복이란 매우 복잡하고 다양한 개념이지만, 철학적으로는 인간의 삶에서 가장 귀중한 목표 중 하나로 여겨집니다. 행복은 주관적인 경험으로, 각자의 가치관과 삶의 목표에 따라 다양하게 해석될 수 있습니다.\n",
            "\n",
            "고대 그리스 철학자 아리스토텔레스는 행복에 대해 \"좋은 행위를 통해 이루어지는 최고의 인간적 가치\"라고 정의했습니다. 이는 인간이 자신의 능력을 최대한 발휘하고 가치 있게 살아가는 것이 행복을 이루는 길이라는 것을 의미합니다.\n",
            "\n",
            "또한 현대 철학자인 존 스튜어트 밀은 행복을 \"만족스러운 삶\"으로 정의했습니다. 이는 자신의 욕구를 충족시키고 내적으로 만족하는 삶을 살아가는 것이 행복을 이루는 요소라는 것을 의미합니다.\n",
            "\n",
            "그러므로 행복은 자신의 가치관과 목표를 실현하고, 내적으로 만족하며 삶을 즐기는 것으로 볼 수 있습니다. 하지만 각자의 상황과 가치관에 따라 행복을 이루는 방식은 다양할 수 있으며, 중요한 것은 자기 자신을 알고 인생을 살아가는 과정에서 행복을 찾아가는 것이라고 할 수 있습니다."
          ]
        }
      ],
      "source": [
        "for chunk in stream:\n",
        "  if chunk.choices and chunk.choices[0].delta.content:\n",
        "    print(chunk.choices[0].delta.content, end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B0YaI3rbBZc",
        "outputId": "3646093d-99c1-4088-8a7f-8be5da588a7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "행복이란 인간이 추구하는 가장 귀중하고 의미 있는 상태 중 하나로 여겨집니다. 철학적으로 행복을 이해하기 위해서는 여러 학파와 철학가들의 관점을 살펴볼 수 있습니다.\n",
            "\n",
            "일반적으로 행복은 스트로이즈와 같은 고대 철학가들이 말한 '유행(유행)에 따른 좋은 삶'으로 정의될 수 있습니다. 즉, 행복은 우리가 가지고 있는 것들에 만족하고, 우리의 욕구와 목표를 달성함으로써 느끼는 만족감과 기쁨이라고 할 수 있습니다.\n",
            "\n",
            "또한 현대 철학에서는 행복을 '심리적 안녕'으로 이해하기도 합니다. 이는 자기 실현, 자아 성취, 사회적 관계의 만족 등 다양한 영역에서 나타날 수 있는 복합적인 요소들을 포함하고 있습니다. 즉, 행복은 단순히 쾌락이나 욕구 충족에 그치는 것이 아니라, 보다 깊은 내적 안정과 만족을 의미한다고 볼 수 있습니다.\n",
            "\n",
            "마지막으로 행복은 '의미 있는 삶'을 살아가는 것과도 관련이 있습니다. 즉, 우리의 행동과 선택이 우리의 가치관과 목적에 부합할 때, 우리는 행복을 느낄 수 있다는 것입니다. 이는 자기 실현과 사회적 기여, 윤리적 행동 등의 요소들을 고려하여 행복을 이해하는 방식이라고 할 수 있습니다.\n",
            "\n",
            "요약하자면, 행복은 단순한 쾌락이나 기쁨에 그치는 것이 아니라, 자아 실현, 내적 안정, 의미 있는 삶을 통해 얻어지는 깊은 만족과 기쁨으로 이해될 수 있습니다. 이러한 관점에서 바라볼 때, 행복을 추구하는 것은 우리가 더 나은 삶을 살아가는 데 중요한 요소가 될 것입니다.\n"
          ]
        }
      ],
      "source": [
        "print(stream.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqLcq8rTij-Y"
      },
      "source": [
        "이미지 생성\n",
        "```\n",
        "dall-e-3 생성형 모델 사용\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A_S9wXPh4le",
        "outputId": "53c88c06-ab1d-4bae-a4d9-568353429252"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ImagesResponse(created=1746584583, data=[Image(b64_json=None, revised_prompt=\"A portrayal of an endearing cat. The feline has shimmering fur, vivid bright eyes and a fluffy tail. It reclines peacefully, showing off its vibrant, soft coat. Surrounding it, there's peaceful ambiance, filled with warm, ambient light casting soft shadows and adding a soothing touch to the image. The cat's playful, innocent demeanor is to be emphasized, its curious eyes looking directly at the viewer, creating a sense of connection and interaction.\", url='https://oaidalleapiprodscus.blob.core.windows.net/private/org-UJIEyxgatUbHDkVDhSHIWSaZ/user-kkq84JNHMRZ9qAUIvon2fPs0/img-roM9fDTHRpL1VCshjcjurUMd.png?st=2025-05-07T01%3A23%3A03Z&se=2025-05-07T03%3A23%3A03Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-05-06T23%3A42%3A15Z&ske=2025-05-07T23%3A42%3A15Z&sks=b&skv=2024-08-04&sig=1nPr28uYQzaZYWEOIwu8CxxbFQ6olZglDCR28o5pRdw%3D')], usage=None)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client = OpenAI()\n",
        "response = client.images.generate(\n",
        "    model=\"dall-e-3\",\n",
        "    prompt=\"귀여운 고양이사진\",\n",
        "    size=\"1024x1024\",\n",
        "    quality=\"standard\",\n",
        "    n=1,\n",
        ")\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "B2YOBrNnjYUd",
        "outputId": "e11765c0-4699-40a3-96ef-78c11eed5427"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-UJIEyxgatUbHDkVDhSHIWSaZ/user-kkq84JNHMRZ9qAUIvon2fPs0/img-roM9fDTHRpL1VCshjcjurUMd.png?st=2025-05-07T01%3A23%3A03Z&se=2025-05-07T03%3A23%3A03Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-05-06T23%3A42%3A15Z&ske=2025-05-07T23%3A42%3A15Z&sks=b&skv=2024-08-04&sig=1nPr28uYQzaZYWEOIwu8CxxbFQ6olZglDCR28o5pRdw%3D'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.data[0].url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEGFssZEkmG7"
      },
      "source": [
        "프롬프트\n",
        "```\n",
        "언어모델에 작업지시를내리를 일종의 명령문\n",
        "Let's think step by step -> 사고 유도형 프롬프트 사용\n",
        "  - 모델이 답을 도출하는 과정을 스스로 설명하면서 더 정확한 답을 도출한다\n",
        "  -실제 논문중에.. 정답률이 10프로대에서 ~ 70프로대로 상승했다는 논문이존재  \n",
        "```\n",
        "좋은 프롬프트를 작성요령\n",
        "```\n",
        "  Instruction : 목표 지시\n",
        "  Context : 맥락(어떤 상황인지)\n",
        "  Constraints : 제약조건( 어떤스타이일또는 언어로 출력)\n",
        "  Format : 출력형식\n",
        "  Examples : 예시 제공(Few-shot 처럼 참고 예시를 포함)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgWiHKrGkKhT",
        "outputId": "ddc9db1d-f15f-4b76-858f-21867b8dd4d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "수도권에서의 당일 여행 코스 추천을 드리겠습니다. \n",
            "\n",
            "1. 아침: 경복궁\n",
            "- 서울의 대표적인 궁전인 경복궁은 한국의 역사와 전통을 만나볼 수 있는 곳입니다. 아침 일찍 방문하여 조용한 분위기에서 궁궐을 산책하며 역사에 관심을 가질 수 있습니다.\n",
            "\n",
            "2. 점심: 인사동\n",
            "- 경복궁에서 인사동까지 걸어가면서 전통적인 한옥 건물과 다양한 문화 상품들을 즐길 수 있습니다. 인사동의 다양한 음식점에서 한식 또는 가끔의 음식을 즐겨보세요.\n",
            "\n",
            "3. 오후: 덕수궁\n",
            "- 인사동에서 걸어서 10분 거리에 있는 덕수궁은 작은 궁전이지만 조용하고 아늑한 분위기를 느낄 수 있는 곳입니다. 사찰 갤러리를 둘러보거나 신라 민속촌을 방문하여 한국 전통 문화에 대해 더 깊이 이해해보세요.\n",
            "\n",
            "4. 저녁: 낙산공원\n",
            "- 여의도 한강공원에서 대표적인 노을을 감상할 수 있는 낙산공원으로 이동합니다. 한강을 바라보며 휴식을 취하거나 산책을 즐기며 하루를 마무리할 수 있습니다.\n",
            "\n",
            "이렇게 수도권에서의 당일 여행코스로 경복궁 → 인사동 → 덕수궁 → 낙산공원을 추천드립니다. 부족한 시간이지만 서울의 역사와 문화를 조금이나마 느낄 수 있는 코스입니다. 즐거운 여행되세요!\n"
          ]
        }
      ],
      "source": [
        "# Zero shot\n",
        "prompt = '수도권 당일 여행코스 추천해줘'\n",
        "result = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"너는 여행스케줄 작성을 하는 전문가\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ])\n",
        "print(result.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK5gmwsfjhrM",
        "outputId": "fe37d012-cf17-42c0-ef5b-f7c885f38a18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "강남역에서 맛집투어를 즐기고 시티투어 버스를 타고 도시의 멋진 야경을 감상하는 멋진 여행 스케줄을 추천해 드릴게요.\n",
            "\n",
            "**낮 시간: 맛집투어**\n",
            "\n",
            "1. **아침:**\n",
            "   - 강남역 근처의 유명한 브런치 카페를 방문하여 맛있는 아침 식사를 즐기세요.\n",
            "   - 근처 한강공원 산책로에서 아침 운동을 즐기거나 한강을 따라 자전거를 타보세요.\n",
            "\n",
            "2. **점심:**\n",
            "   - 가로수길, 청담동, 압구정 혹은 신사동 등 강남의 유명한 맛집들을 돌아다니며 다양한 음식을 맛보세요.\n",
            "\n",
            "**저녁 시간: 시티투어**\n",
            "\n",
            "1. **오후:**\n",
            "   - 강남역에서 시티투어 버스를 타고 서울의 대표적인 관광 명소를 순회하며 도심의 모습을 감상하세요.\n",
            "   - 남산타워, 광화문, 인사동 등을 방문하여 사진을 찍으며 도심의 아름다운 야경을 즐겨보세요.\n",
            "\n",
            "2. **저녁:**\n",
            "   - 시티투어를 마치고 강남역 근처에서 강남 맛집을 다시 찾아 방문하여 저녁 식사를 즐기세요.\n",
            "\n",
            "이렇게 멋진 강남역 맛집투어와 시티투어를 즐기면서 하루를 특별하게 보낼 수 있을 것 같아요. 즐거운 여행되세요!\n"
          ]
        }
      ],
      "source": [
        "# One shot\n",
        "prompt = '강남역에서 맛집투어를 하고 시티투어 버스를타고 도시 야경을 보는 것처럼 여행스케줄 추천해줘'\n",
        "result = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"너는 여행스케줄 작성을 하는 전문가\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ])\n",
        "print(result.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aurocssOm1vk",
        "outputId": "88f61129-986d-4aa0-f911-52f3a1a6253a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "강남역 맛집투어 & 시티투어 코스\n",
            "1. 강남역 근처 맛집 탐방\n",
            "- 아침: \"이디야\"에서 간단히 커피와 빵을 즐기며 출발\n",
            "- 점심: \"고스트키친\"에서 맛있는 버거와 감자튀김 즐기기\n",
            "- 저녁: \"엘살바도르\"에서 멕시코 음식과 칵테일 즐기기\n",
            "\n",
            "2. 시티투어 버스 탑승\n",
            "- 코엑스 맞은편 출발 및 경유지에서 강남, 압구정, 청담, 신사 등의 명소 감상\n",
            "- 노을 지는 서울 시티 야경 감상 포인트로 이동\n",
            "\n",
            "부산 오뎅 & 자갈치 시장 광어회 맛집투어\n",
            "1. 부산 오뎅 맛집 탐방\n",
            "- 아침: 부산역 근처 \"이디야\"에서 커피와 간단한 아침 식사\n",
            "- 오전: 부산 오뎅 명소 \"성포동 오뎅길\"에서 다양한 오뎅 맛보기\n",
            "- 점심: \"본가막회\"에서 신선한 막회와 막국수 즐기기\n",
            "\n",
            "2. 자갈치 시장 광어회 맛집 탐방\n",
            "- 오후: 부산 자갈치 시장으로 이동하여 현지 신선한 광어회 맛집 탐방\n",
            "- 저녁: \"이나니와\"에서 광어회 정식을 즐기며 부산의 바다 맛을 만끽하기\n",
            "\n",
            "이렇게 여행 계획을 세우면 맛집과 관광지를 동시에 즐길 수 있어요. 부산과 서울에서의 맛있는 여행 되시길 바래요.\n"
          ]
        }
      ],
      "source": [
        "# Few shot\n",
        "prompt = '강남역에서 맛집투어를 하고 시티투어 버스를타고 도시 야경을 보는 코스, 부산에서 오뎅을 먹고 자갈치 시장에서 광어회 먹는 것처럼 맛집투어 만들어줘'\n",
        "result = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"너는 여행스케줄 작성을 하는 전문가\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ])\n",
        "print(result.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syb3mOOhncD1"
      },
      "source": [
        "Cot\n",
        "  - Chain of Thought : 모델이 스스로 사고과정을 구성\n",
        "    - 단계적으로 생각(알려줘)해줘\n",
        "    - 왜 그렇게 되는지 논리적으로 설명해줘\n",
        "ReAct(Resoning + Action)\n",
        "  - 모델이 생각과 행동을 번갈아 가면서 수행하게 유도\n",
        "    - ~~~ 가 왜 그런지 자세하게 설명하면서 단계적으로 풀이해줘\n",
        "Self-Ask : 질문 분해 전략\n",
        "  - 이게 왜 이렇게 되는지 단계적으로 알려줘(단계적으로 설명해봐)\n",
        "Multi-turn\n",
        "  - 역활을 나누고 대화를 쌓아가면서 맥락을 유지\n",
        "  - 가상 assistnat 와 user의 역활을 구성          \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVRWBp2btjT2"
      },
      "source": [
        "파인튜닝 : 미세조정\n",
        "  - gpt모델은 방대한양의 텍스트에 대해서 사전 학습\n",
        "  - 효과적으로 사용하려면 원하는 도메인 데이터에 대해서 재 학습을해서 해당 도메인에 대한 좀더 강력한 모델을 만드는것\n",
        "프롬프트 체인: 복잡한 작업을 여러 프롬프트로 나눈다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZt7q7hl0IUE"
      },
      "source": [
        "아래와같은 형식으로 확장자를 filename.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Pf1_VNC12CR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "data = {\n",
        "    'system' : ['너는 친절한 AI','너는 친절한 AI'],\n",
        "    'user' : ['오늘 날씨 어때','파이썬으로 크롤링해줘'],\n",
        "    'assistant' : ['오늘은 맑고 기온은 20도 입니다.','BeautifulSoup를 사용할 수 있습니다.']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "# jsonl로 변환\n",
        "with open(\"mydata.jsonl\",'w',encoding='utf-8') as f:\n",
        "  for _, row in df.iterrows():\n",
        "      messages = [\n",
        "          {\"role\": \"system\", \"content\": row['system']},\n",
        "          {\"role\": \"user\", \"content\": row['user']},\n",
        "          {\"role\": \"assistant\", \"content\": row['assistant']}\n",
        "      ]\n",
        "      json.dump({\"messages\" : messages}, f, ensure_ascii=False)\n",
        "      f.write('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFaXWLlDNpBc"
      },
      "source": [
        "fine tuning 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4L52DvFzf3E",
        "outputId": "8eed2928-0c60-4884-d973-ae3b98845d86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "대한민국의 현재 인구수는 약 5천만 명입니다.\n"
          ]
        }
      ],
      "source": [
        "prompt = '대한민국의 현재 인구수 알려주세요'\n",
        "result = client.chat.completions.create(\n",
        "    model=\"ft:gpt-3.5-turbo-0125:personal::BURWyXGK\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"너는 QA 전문가\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ])\n",
        "print(result.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTl2Xv9aO-f3"
      },
      "source": [
        "파인튜닝 모델 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWtpdmu4N8e9"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key='api-key')\n",
        "# 데이터 업로드\n",
        "with open(\"mydata.jsonl\", \"rb\") as f:\n",
        "  file_response = client.files.create(file=f, purpose='fine-tune')\n",
        "file_id = file_response.id\n",
        "# 파인튜닝\n",
        "fine_tune_response =  client.fine_tuning.jobs.create(\n",
        "  training_file=file_id,\n",
        "  model=\"gpt-3.5-turbo\"\n",
        ")\n",
        "fine_tune_id = fine_tune_response.id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WuTOXAjQPev",
        "outputId": "d4a34384-cca9-4127-dd4d-bbc1f5c82b2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "succeeded\n"
          ]
        }
      ],
      "source": [
        "#상태확인\n",
        "status = client.fine_tuning.jobs.retrieve(fine_tune_id)\n",
        "print(status.status)  # pendding, running, successed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlxenQJiQ0zZ",
        "outputId": "346e3adc-b7d6-48d6-8dec-ece4b250b5aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('file-8P8k8jq8ug3f3o51AcHXgm',\n",
              " 'ftjob-VZIYCnQY75mwj4mnJpXlvTWc',\n",
              " 'ft:gpt-3.5-turbo-0125:personal::BURsRF7z')"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_id, fine_tune_id,status.fine_tuned_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOpqlCDnRJEL",
        "outputId": "91503d5a-9ffc-4f1e-f1e8-3a4e329b6150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "대한민국의 현재 인구는 약 5,117만 명입니다.\n"
          ]
        }
      ],
      "source": [
        "prompt = '대한민국의 현재 인구수 알려주세요'\n",
        "result = client.chat.completions.create(\n",
        "    model=status.fine_tuned_model,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"너는 QA 전문가\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ])\n",
        "print(result.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlgT2ieUWP7L"
      },
      "source": [
        "1. fine-tuning 데이터\n",
        "  - QA데이터 업로드\n",
        "  - fine tuning 학습\n",
        "  - 학습된 모델을 로드해서 실행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w0Rdj_NXSg5"
      },
      "source": [
        "# 파일 업로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHgbuX9cSTlb"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "# openai key 입력\n",
        "client = OpenAI(api_key='api-key')\n",
        "# 데이터 업로드\n",
        "with open(\"mydata.jsonl\", \"rb\") as f:\n",
        "  file_response = client.files.create(file=f, purpose='fine-tune')\n",
        "file_id = file_response.id\n",
        "print(f'업로드 파일 아이디 : {file_id}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mdqnViBXoey"
      },
      "source": [
        "# 업로드된 파일을 파인튜닝"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zc-2TfsnR5q5"
      },
      "outputs": [],
      "source": [
        "# 파인튜닝\n",
        "fine_tune_response =  client.fine_tuning.jobs.create(\n",
        "  training_file=file_id,\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  hyperparameters={\n",
        "      'n_epochs' : 1,\n",
        "      'learning_rate_multiplier' : 0.1,  # 기본학습률(1e-3  0.001)에 0.1을 곱한다.  학습률 배수\n",
        "      'batch_size': 1\n",
        "  }\n",
        ")\n",
        "fine_tune_id = fine_tune_response.id\n",
        "print(f'파인튜닝 아이디 : {fine_tune_id}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIRKl_ghXtiA"
      },
      "source": [
        "# 상태확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQULmduOX2Aa"
      },
      "outputs": [],
      "source": [
        "#상태확인\n",
        "status = client.fine_tuning.jobs.retrieve(fine_tune_id)\n",
        "print(status.status)  # pendding, running, successed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU9Vhs4LX3GS"
      },
      "source": [
        "# 파인튜닝된 모델 확인 및 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6LoWJlmX6G3"
      },
      "outputs": [],
      "source": [
        "print(f'파인튜닝된 모델 : {status.fine_tuned_model}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVtxm3hcYE50"
      },
      "outputs": [],
      "source": [
        "prompt = '대한민국의 현재 인구수 알려주세요'\n",
        "result = client.chat.completions.create(\n",
        "    model=status.fine_tuned_model,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"너는 QA 전문가\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ])\n",
        "print(result.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnM1ytiWcUJE"
      },
      "source": [
        "#한국어 QA 데이터  \n",
        "  - https://github.com/korquad/korquad.github.io/blob/master/dataset/KorQuAD_v1.0_train.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSqU84n6cXw3"
      },
      "outputs": [],
      "source": [
        "json_file = '/content/drive/MyDrive/data/KorQuAD_v1.0_train (1).json'\n",
        "# 1.json 파일 읽기\n",
        "# 2. 파인튜닝 파일 포멧 맞추기\n",
        "# {\"messages\": [{\"role\": \"system\", \"content\": \"너는 친절한 AI\"}, {\"role\": \"user\", \"content\": \"지구의 위성은 뭐야?\"}, {\"role\": \"assistant\", \"content\": \"지구의 유일한 자연 위성은 달입니다.\"}]}\n",
        "# 3. 파일을 openai 에 올리기\n",
        "# 4. openai로 파인튜닝하기 - 필요하면 hyperparameter 사용  suffix 옵션을 사용하면 모델명 특정 문자열을 추가\n",
        "# 5. 학습이 끝나면 파인튜닝한 모델이름으로 모델 불러와서 사용하"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGrMhEiYdgih"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(json_file,'r',encoding='utf-8') as f:\n",
        "  data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxte_YytftZD",
        "outputId": "f5b4999b-bca0-4d87-bbc3-0798f41fcce5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1420"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data['data'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRfCgXz-hkzC"
      },
      "outputs": [],
      "source": [
        "new_data = data['data'][:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR03ramSj2MD"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"너는 친절한 AI\"},\n",
        "{\"role\": \"user\", \"content\": \"세계에서 가장 높은 산은 어디야?\"},\n",
        "{\"role\": \"assistant\", \"content\": \"세계에서 가장 높은 산은 에베레스트산이며, 높이는 약 8,848미터입니다.\"}]}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fyYPjbNPh8Gi",
        "outputId": "8919abaf-1249-4c27-d806-ca1cd83d4dcb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'교향곡'"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_data[0]['paragraphs'][0]['qas'][0]['question']\n",
        "new_data[0]['paragraphs'][0]['qas'][0]['answers'][0]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "emm3FlnOjp47"
      },
      "outputs": [],
      "source": [
        "# jsonl로 변환\n",
        "with open(\"2025_05_07_02.jsonl\",'w',encoding='utf-8') as f:\n",
        "  for row in new_data[0]['paragraphs']:\n",
        "      for row in row['qas']:\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"너는 친절한 AI야 사용자의 질문에 문맥을 참고해서 정답을 알려\"},\n",
        "            {\"role\": \"user\", \"content\": row['question']},\n",
        "            {\"role\": \"assistant\", \"content\": row['answers'][0]['text']}\n",
        "        ]\n",
        "        json.dump({\"messages\" : messages}, f, ensure_ascii=False)\n",
        "        f.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QMbvuP--lfFh",
        "outputId": "da1afb3e-411d-4237-8355-35ade6e86317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "업로드 파일 아이디 : file-FarumWTVNLsbrn7EEC2YxL\n",
            "파인튜닝 job 아이디 : ftjob-ZxfsbAgZHtlR3YbUaZC7PVhR\n",
            "validating_files\n",
            "validating_files\n",
            "validating_files\n",
            "validating_files\n",
            "validating_files\n",
            "validating_files\n",
            "queued\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "succeeded\n",
            "파인튜닝된 모델 : ft:gpt-3.5-turbo-0125:personal::BUUhJKca\n",
            "교향곡 9번 '합창곡'\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "# openai key 입력\n",
        "client = OpenAI(api_key='api-key')\n",
        "# 데이터 업로드\n",
        "with open(\"/content/2025_05_07_02.jsonl\", \"rb\") as f:\n",
        "  file_response = client.files.create(file=f, purpose='fine-tune')\n",
        "file_id = file_response.id\n",
        "print(f'업로드 파일 아이디 : {file_id}')\n",
        "\n",
        "# 파인튜닝\n",
        "fine_tune_response =  client.fine_tuning.jobs.create(\n",
        "  training_file=file_id,\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  hyperparameters={\n",
        "      'n_epochs' : 3,\n",
        "      'learning_rate_multiplier' : 1.0,  # 기본학습률(1e-3  0.001)에 0.1을 곱한다.  학습률 배수\n",
        "      'batch_size': 2\n",
        "  }\n",
        ")\n",
        "fine_tune_id = fine_tune_response.id\n",
        "print(f'파인튜닝 job 아이디 : {fine_tune_id}')\n",
        "\n",
        "#상태확인\n",
        "status = client.fine_tuning.jobs.retrieve(fine_tune_id)\n",
        "import time\n",
        "while status.status != 'succeeded':\n",
        "  time.sleep(10)\n",
        "  status = client.fine_tuning.jobs.retrieve(fine_tune_id)\n",
        "  print(status.status)\n",
        "# print(status.status)  # pendding, running, successed\n",
        "print(f'파인튜닝된 모델 : {status.fine_tuned_model}')\n",
        "\n",
        "prompt = '베토벤의 대표작은?'\n",
        "result = client.chat.completions.create(\n",
        "    model=status.fine_tuned_model,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"너는 친절한 AI야 사용자의 질문에 문맥을 참고해서 정답을 알려줘\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ])\n",
        "print(result.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "collapsed": true,
        "id": "1Pd84G16zafH",
        "outputId": "94662423-3b21-4b78-89d3-0f8fa88a4961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "결과파일 id : file-AUa7XydZ8ppHEHheckHVY8\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "Out of range float values are not JSON compliant: nan",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9e066bbf-473f-42e6-8f0f-43c954eab599\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c3RlcCx0cmFpbl9sb3NzLHRyYWluX2FjY3VyYWN5LHZhbGlkX2xvc3MsdmFsaWRfbWVhbl90b2tlbl9hY2N1cmFjeSx0cmFpbl9tZWFuX3Jld2FyZCxmdWxsX3ZhbGlkYXRpb25fbWVhbl9yZXdhcmQKMSw0LjM0NzAxLDAuNjQ3MDYsLCwsCjIsNC4yMjQ4MSwwLjU4ODI0LCwsLAozLDMuNjIxOTksMC43NSwsLCwKNCwzLjk5NSwwLjY0NzA2LCwsLAo1LDYuMDIwNjEsMC4yNSwsLCwKNiwzLjIyMzM1LDAuNjQ3MDYsLCwsCjcsMy4wOTU5MywwLjY2NjY3LCwsLAo4LDEuMzIzMjYsMC42ODc1LCwsLAo5LDEuODE2NzMsMC42OTU2NSwsLCwKMTAsMi42OTg0MywwLjUzODQ2LCwsLAoxMSwxLjUxMTI5LDAuODU3MTQsLCwsCjEyLDAuNDUyNjYsMC44NzUsLCwsCjEzLDEuMTA3NDksMC44MTI1LCwsLAoxNCwxLjk1MDUxLDAuNjc3NDIsLCwsCjE1LDEuMDQxOTksMC43NjkyMywsLCwKMTYsMi41MTQwMSwwLjUzODQ2LCwsLAoxNywxLjA1Mzc3LDAuNzE0MjksLCwsCjE4LDEuNjE5NDMsMC41ODMzMywsLCwKMTksMC4zNDA5MiwwLjkxNjY3LCwsLAoyMCwxLjA4NTQ5LDAuODg4ODksLCwsCjIxLDAuODA4NjcsMC44NzUsLCwsCjIyLDAuODE2MjYsMC44Mjc1OSwsLCwKMjMsMS4wMjE1OSwwLjgzMzMzLCwsLAoyNCwwLjYyNCwwLjg2NjY3LCwsLAoyNSwwLjUxODE0LDAuOCwsLCwKMjYsMC4xMTQ0MiwwLjk1ODMzLCwsLAoyNywxLjU0NzgzLDAuNjY2NjcsLCwsCjI4LDAuMTg0MTUsMS4wLCwsLAoyOSwwLjcxNjg1LDAuODY2NjcsLCwsCjMwLDIuMDEwMSwwLjYzNjM2LCwsLAozMSwxLjIzMzkzLDAuNjg0MjEsLCwsCjMyLDAuNDk2OTQsMC45MDkwOSwsLCwKMzMsMC41MjI0OSwwLjc4NTcxLCwsLAozNCwwLjU5MywwLjkyMzA4LCwsLAozNSwwLjQ1NjYsMC44ODg4OSwsLCwKMzYsMS4wNjA3MSwwLjg2NjY3LCwsLAo=</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e066bbf-473f-42e6-8f0f-43c954eab599')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9e066bbf-473f-42e6-8f0f-43c954eab599 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9e066bbf-473f-42e6-8f0f-43c954eab599');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [c3RlcCx0cmFpbl9sb3NzLHRyYWluX2FjY3VyYWN5LHZhbGlkX2xvc3MsdmFsaWRfbWVhbl90b2tlbl9hY2N1cmFjeSx0cmFpbl9tZWFuX3Jld2FyZCxmdWxsX3ZhbGlkYXRpb25fbWVhbl9yZXdhcmQKMSw0LjM0NzAxLDAuNjQ3MDYsLCwsCjIsNC4yMjQ4MSwwLjU4ODI0LCwsLAozLDMuNjIxOTksMC43NSwsLCwKNCwzLjk5NSwwLjY0NzA2LCwsLAo1LDYuMDIwNjEsMC4yNSwsLCwKNiwzLjIyMzM1LDAuNjQ3MDYsLCwsCjcsMy4wOTU5MywwLjY2NjY3LCwsLAo4LDEuMzIzMjYsMC42ODc1LCwsLAo5LDEuODE2NzMsMC42OTU2NSwsLCwKMTAsMi42OTg0MywwLjUzODQ2LCwsLAoxMSwxLjUxMTI5LDAuODU3MTQsLCwsCjEyLDAuNDUyNjYsMC44NzUsLCwsCjEzLDEuMTA3NDksMC44MTI1LCwsLAoxNCwxLjk1MDUxLDAuNjc3NDIsLCwsCjE1LDEuMDQxOTksMC43NjkyMywsLCwKMTYsMi41MTQwMSwwLjUzODQ2LCwsLAoxNywxLjA1Mzc3LDAuNzE0MjksLCwsCjE4LDEuNjE5NDMsMC41ODMzMywsLCwKMTksMC4zNDA5MiwwLjkxNjY3LCwsLAoyMCwxLjA4NTQ5LDAuODg4ODksLCwsCjIxLDAuODA4NjcsMC44NzUsLCwsCjIyLDAuODE2MjYsMC44Mjc1OSwsLCwKMjMsMS4wMjE1OSwwLjgzMzMzLCwsLAoyNCwwLjYyNCwwLjg2NjY3LCwsLAoyNSwwLjUxODE0LDAuOCwsLCwKMjYsMC4xMTQ0MiwwLjk1ODMzLCwsLAoyNywxLjU0NzgzLDAuNjY2NjcsLCwsCjI4LDAuMTg0MTUsMS4wLCwsLAoyOSwwLjcxNjg1LDAuODY2NjcsLCwsCjMwLDIuMDEwMSwwLjYzNjM2LCwsLAozMSwxLjIzMzkzLDAuNjg0MjEsLCwsCjMyLDAuNDk2OTQsMC45MDkwOSwsLCwKMzMsMC41MjI0OSwwLjc4NTcxLCwsLAozNCwwLjU5MywwLjkyMzA4LCwsLAozNSwwLjQ1NjYsMC44ODg4OSwsLCwKMzYsMS4wNjA3MSwwLjg2NjY3LCwsLAo=]\n",
              "Index: []"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 결과파일을 다운로드\n",
        "print(f'결과파일 id : {status.result_files[0]}')\n",
        "file_content = client.files.content(status.result_files[0])\n",
        "with open(\"result.csv\", \"wb\") as f:\n",
        "  f.write(file_content.read())\n",
        "df = pd.read_csv('result.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMCkj3iP4qc_",
        "outputId": "60ba603f-8506-499b-e9fd-e26fb74bb33d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-ZxfsbAgZHtlR3YbUaZC7PVhR', created_at=1746607282, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::BUUhJKca', finished_at=1746607539, hyperparameters=Hyperparameters(batch_size=2, learning_rate_multiplier=1.0, n_epochs=3), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-UJIEyxgatUbHDkVDhSHIWSaZ', result_files=['file-AUa7XydZ8ppHEHheckHVY8'], seed=1556968097, status='succeeded', trained_tokens=5751, training_file='file-FarumWTVNLsbrn7EEC2YxL', validation_file=None, estimated_finish=None, integrations=[], metadata=None, method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size=2, learning_rate_multiplier=1.0, n_epochs=3)), type='supervised'), user_provided_suffix=None, usage_metrics=None, shared_with_openai=False)"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vVd9kto7FNE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
